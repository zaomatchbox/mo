{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При чтении будем хранить данные в переменной `CACHE`, чтобы ускорить загрузку. В случае их обновления, достаточно вызвать `read(override=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_DATASET_DIR = '../../nmnist/notMNIST_small/'\n",
    "LARGE_DATASET_DIR = '../../nmnist/notMNIST_large/'\n",
    "CACHE = {}\n",
    "LABEL_MAP = {}\n",
    "INV_LABEL_MAP = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data_dir, override=False):\n",
    "    f_v = 0\n",
    "    global CACHE\n",
    "    if not CACHE.get(data_dir, []) or override:\n",
    "        CACHE[data_dir] = []\n",
    "        X, y = [], []\n",
    "        for f in tqdm(os.listdir(data_dir), desc='Letter'):\n",
    "            if not f.startswith('.'):\n",
    "                img_dir = os.path.join(data_dir, f)\n",
    "                for img in os.listdir(img_dir):\n",
    "                    img_path = os.path.join(img_dir, img)\n",
    "                    data = cv2.imread(img_path, 0)\n",
    "                    if data is None:\n",
    "                        continue\n",
    "                    X.append(data * 2 / 255 - 1)\n",
    "                    if LABEL_MAP.get(f) is None:\n",
    "                        LABEL_MAP[f] = f_v\n",
    "                        INV_LABEL_MAP[f_v] = f\n",
    "                        f_v += 1\n",
    "                    y.append(LABEL_MAP[f])\n",
    "        CACHE[data_dir].append(np.array(X))\n",
    "        CACHE[data_dir].append(np.array(y))\n",
    "    return CACHE[data_dir][0], CACHE[data_dir][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, verbose=False, override=False):\n",
    "    X, y = read(data_dir, override=override)\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    N = X.shape[0]\n",
    "    if verbose:\n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "        print(X[:5])\n",
    "        print(y[:5])\n",
    "        print(np.unique(y))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(data_dir, size=(0.7, 0.3), verbose=False, random_state=6, override=False):\n",
    "    X, y = shuffle(*get_data(data_dir, verbose=verbose, override=override), random_state=random_state)\n",
    "    assert abs(np.sum(size) - 1.0) < 0.001\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size[1], random_state=random_state)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59c37d148f2425b974f7e5ced4da29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Letter', max=10, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_split_data(LARGE_DATASET_DIR, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем настройки из запуска на малом датасете, а также изменим их немного под большой датасет: `lr = 0.1`, `epochs = 20`, функции активации `ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)\n",
      "Learning rate: 0.1\n",
      "Epochs: 20\n",
      "\n",
      "Epoch 1/20\n",
      "370379/370379 [==============================] - 264s 714us/step - loss: 0.5083 - acc: 0.8420\n",
      "Epoch 2/20\n",
      "370379/370379 [==============================] - 113s 305us/step - loss: 0.3941 - acc: 0.8774\n",
      "Epoch 3/20\n",
      "370379/370379 [==============================] - 75s 204us/step - loss: 0.3549 - acc: 0.8892\n",
      "Epoch 4/20\n",
      "370379/370379 [==============================] - 67s 180us/step - loss: 0.3309 - acc: 0.8966\n",
      "Epoch 5/20\n",
      "370379/370379 [==============================] - 65s 175us/step - loss: 0.3140 - acc: 0.9013\n",
      "Epoch 6/20\n",
      "370379/370379 [==============================] - 77s 207us/step - loss: 0.3001 - acc: 0.9058\n",
      "Epoch 7/20\n",
      "370379/370379 [==============================] - 79s 214us/step - loss: 0.2888 - acc: 0.9090\n",
      "Epoch 8/20\n",
      "370379/370379 [==============================] - 66s 179us/step - loss: 0.2779 - acc: 0.9119\n",
      "Epoch 9/20\n",
      "370379/370379 [==============================] - 71s 191us/step - loss: 0.2698 - acc: 0.9145\n",
      "Epoch 10/20\n",
      "370379/370379 [==============================] - 77s 207us/step - loss: 0.2628 - acc: 0.9166\n",
      "Epoch 11/20\n",
      "370379/370379 [==============================] - 72s 195us/step - loss: 0.2556 - acc: 0.9187\n",
      "Epoch 12/20\n",
      "370379/370379 [==============================] - 73s 196us/step - loss: 0.2495 - acc: 0.9207\n",
      "Epoch 13/20\n",
      "370379/370379 [==============================] - 75s 204us/step - loss: 0.2434 - acc: 0.9220\n",
      "Epoch 14/20\n",
      "370379/370379 [==============================] - 72s 195us/step - loss: 0.2378 - acc: 0.9240\n",
      "Epoch 15/20\n",
      "370379/370379 [==============================] - 68s 183us/step - loss: 0.2324 - acc: 0.9258\n",
      "Epoch 16/20\n",
      "370379/370379 [==============================] - 72s 194us/step - loss: 0.2280 - acc: 0.9268\n",
      "Epoch 17/20\n",
      "370379/370379 [==============================] - 68s 185us/step - loss: 0.2231 - acc: 0.9283\n",
      "Epoch 18/20\n",
      "370379/370379 [==============================] - 106s 287us/step - loss: 0.2197 - acc: 0.9293\n",
      "Epoch 19/20\n",
      "370379/370379 [==============================] - 74s 199us/step - loss: 0.2158 - acc: 0.9309\n",
      "Epoch 20/20\n",
      "370379/370379 [==============================] - 68s 185us/step - loss: 0.2131 - acc: 0.9315\n",
      "158735/158735 [==============================] - 28s 174us/step\n",
      "Loss: 0.33970796888758176\n",
      "Accuracy: 0.9031026553690112\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "epochs = 20\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(lr), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добавить dropout (используем небольшой коэффициент, как рекомендуется здесь: https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "\n",
    "```Generally, use a small dropout value of 20%-50% of neurons with 20% providing a good starting point. A probability too low has minimal effect and a value too high results in under-learning by the network.```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 128(relu) - 32(tanh) - 10(softmax)\n",
      "Learning rate: 0.1\n",
      "Epochs: 20\n",
      "\n",
      "Epoch 1/20\n",
      "370379/370379 [==============================] - 133s 359us/step - loss: 0.5844 - acc: 0.8217\n",
      "Epoch 2/20\n",
      "370379/370379 [==============================] - 102s 275us/step - loss: 0.4810 - acc: 0.8517\n",
      "Epoch 3/20\n",
      "370379/370379 [==============================] - 106s 286us/step - loss: 0.4489 - acc: 0.8612\n",
      "Epoch 4/20\n",
      "370379/370379 [==============================] - 114s 308us/step - loss: 0.4281 - acc: 0.8676\n",
      "Epoch 5/20\n",
      "370379/370379 [==============================] - 111s 301us/step - loss: 0.4132 - acc: 0.8720\n",
      "Epoch 6/20\n",
      "370379/370379 [==============================] - 109s 295us/step - loss: 0.4013 - acc: 0.8759\n",
      "Epoch 7/20\n",
      "370379/370379 [==============================] - 100s 271us/step - loss: 0.3935 - acc: 0.8782\n",
      "Epoch 8/20\n",
      "370379/370379 [==============================] - 104s 281us/step - loss: 0.3854 - acc: 0.8808\n",
      "Epoch 9/20\n",
      "370379/370379 [==============================] - 103s 279us/step - loss: 0.3790 - acc: 0.8828\n",
      "Epoch 10/20\n",
      "370379/370379 [==============================] - 96s 260us/step - loss: 0.3742 - acc: 0.8844\n",
      "Epoch 11/20\n",
      "370379/370379 [==============================] - 94s 253us/step - loss: 0.3695 - acc: 0.8857\n",
      "Epoch 12/20\n",
      "370379/370379 [==============================] - 97s 262us/step - loss: 0.3654 - acc: 0.8867\n",
      "Epoch 13/20\n",
      "370379/370379 [==============================] - 95s 255us/step - loss: 0.3603 - acc: 0.8884\n",
      "Epoch 14/20\n",
      "370379/370379 [==============================] - 90s 244us/step - loss: 0.3563 - acc: 0.8898\n",
      "Epoch 15/20\n",
      "370379/370379 [==============================] - 99s 266us/step - loss: 0.3542 - acc: 0.8901\n",
      "Epoch 16/20\n",
      "370379/370379 [==============================] - 97s 263us/step - loss: 0.3506 - acc: 0.8913\n",
      "Epoch 17/20\n",
      "370379/370379 [==============================] - 89s 240us/step - loss: 0.3473 - acc: 0.8924\n",
      "Epoch 18/20\n",
      "370379/370379 [==============================] - 94s 253us/step - loss: 0.3440 - acc: 0.8930\n",
      "Epoch 19/20\n",
      "370379/370379 [==============================] - 96s 259us/step - loss: 0.3418 - acc: 0.8941\n",
      "Epoch 20/20\n",
      "370379/370379 [==============================] - 95s 258us/step - loss: 0.3383 - acc: 0.8949\n",
      "158735/158735 [==============================] - 27s 168us/step\n",
      "Loss: 0.3250090445377254\n",
      "Accuracy: 0.8995054650836904\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "epochs = 20\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 128(relu) - 32(tanh) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(lr), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что модель давала прогресс на эпохах, докинем еще 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "370379/370379 [==============================] - 122s 328us/step - loss: 0.3374 - acc: 0.8952\n",
      "Epoch 2/15\n",
      "370379/370379 [==============================] - 93s 252us/step - loss: 0.3362 - acc: 0.8956\n",
      "Epoch 3/15\n",
      "370379/370379 [==============================] - 94s 253us/step - loss: 0.3338 - acc: 0.8960\n",
      "Epoch 4/15\n",
      "370379/370379 [==============================] - 98s 265us/step - loss: 0.3327 - acc: 0.8966\n",
      "Epoch 5/15\n",
      "370379/370379 [==============================] - 94s 255us/step - loss: 0.3300 - acc: 0.8975\n",
      "Epoch 6/15\n",
      "370379/370379 [==============================] - 94s 253us/step - loss: 0.3292 - acc: 0.8978\n",
      "Epoch 7/15\n",
      "370379/370379 [==============================] - 98s 264us/step - loss: 0.3259 - acc: 0.8988\n",
      "Epoch 8/15\n",
      "370379/370379 [==============================] - 95s 257us/step - loss: 0.3242 - acc: 0.8988\n",
      "Epoch 9/15\n",
      "370379/370379 [==============================] - 99s 269us/step - loss: 0.3227 - acc: 0.8997\n",
      "Epoch 10/15\n",
      "370379/370379 [==============================] - 130s 350us/step - loss: 0.3220 - acc: 0.8996\n",
      "Epoch 11/15\n",
      "370379/370379 [==============================] - 154s 415us/step - loss: 0.3192 - acc: 0.9007\n",
      "Epoch 12/15\n",
      "370379/370379 [==============================] - 152s 410us/step - loss: 0.3188 - acc: 0.9010\n",
      "Epoch 13/15\n",
      "370379/370379 [==============================] - 108s 292us/step - loss: 0.3177 - acc: 0.9013\n",
      "Epoch 14/15\n",
      "370379/370379 [==============================] - 103s 278us/step - loss: 0.3165 - acc: 0.9014\n",
      "Epoch 15/15\n",
      "370379/370379 [==============================] - 101s 273us/step - loss: 0.3152 - acc: 0.9015\n",
      "158735/158735 [==============================] - 21s 135us/step\n",
      "Loss: 0.3076896562316675\n",
      "Accuracy: 0.9052823888875144\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=15)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить динамический (адаптивный) коэффициент обучения. Для этого воспользуемся методом `Adam`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 128(relu) - 32(tanh) - 10(softmax)\n",
      "Learning rate: 0.001\n",
      "Epochs: 30\n",
      "\n",
      "Epoch 1/30\n",
      "370379/370379 [==============================] - 255s 687us/step - loss: 0.6472 - acc: 0.8045\n",
      "Epoch 2/30\n",
      "370379/370379 [==============================] - 183s 494us/step - loss: 0.5659 - acc: 0.8279\n",
      "Epoch 3/30\n",
      "370379/370379 [==============================] - 179s 483us/step - loss: 0.5410 - acc: 0.8350\n",
      "Epoch 4/30\n",
      "370379/370379 [==============================] - 170s 459us/step - loss: 0.5282 - acc: 0.8386\n",
      "Epoch 5/30\n",
      "370379/370379 [==============================] - 187s 504us/step - loss: 0.5212 - acc: 0.8408\n",
      "Epoch 6/30\n",
      "370379/370379 [==============================] - 202s 546us/step - loss: 0.5131 - acc: 0.8428\n",
      "Epoch 7/30\n",
      "370379/370379 [==============================] - 215s 580us/step - loss: 0.5091 - acc: 0.8438\n",
      "Epoch 8/30\n",
      "370379/370379 [==============================] - 184s 498us/step - loss: 0.5048 - acc: 0.8458\n",
      "Epoch 9/30\n",
      "370379/370379 [==============================] - 196s 530us/step - loss: 0.4981 - acc: 0.8481\n",
      "Epoch 10/30\n",
      "370379/370379 [==============================] - 161s 435us/step - loss: 0.4951 - acc: 0.8483\n",
      "Epoch 11/30\n",
      "370379/370379 [==============================] - 162s 438us/step - loss: 0.4917 - acc: 0.8499\n",
      "Epoch 12/30\n",
      "370379/370379 [==============================] - 157s 424us/step - loss: 0.4866 - acc: 0.8514\n",
      "Epoch 13/30\n",
      "370379/370379 [==============================] - 175s 472us/step - loss: 0.4840 - acc: 0.8523\n",
      "Epoch 14/30\n",
      "370379/370379 [==============================] - 156s 421us/step - loss: 0.4818 - acc: 0.8523\n",
      "Epoch 15/30\n",
      "370379/370379 [==============================] - 158s 427us/step - loss: 0.4818 - acc: 0.8523\n",
      "Epoch 16/30\n",
      "370379/370379 [==============================] - 158s 428us/step - loss: 0.4780 - acc: 0.8538\n",
      "Epoch 17/30\n",
      "370379/370379 [==============================] - 157s 424us/step - loss: 0.4764 - acc: 0.8543\n",
      "Epoch 18/30\n",
      "370379/370379 [==============================] - 212s 572us/step - loss: 0.4756 - acc: 0.8548\n",
      "Epoch 19/30\n",
      "370379/370379 [==============================] - 279s 752us/step - loss: 0.4717 - acc: 0.8562\n",
      "Epoch 20/30\n",
      "370379/370379 [==============================] - 231s 624us/step - loss: 0.4695 - acc: 0.8571\n",
      "Epoch 21/30\n",
      "370379/370379 [==============================] - 255s 687us/step - loss: 0.4685 - acc: 0.8566\n",
      "Epoch 22/30\n",
      "370379/370379 [==============================] - 253s 684us/step - loss: 0.4675 - acc: 0.8568\n",
      "Epoch 23/30\n",
      "370379/370379 [==============================] - 233s 628us/step - loss: 0.4658 - acc: 0.8578\n",
      "Epoch 24/30\n",
      "370379/370379 [==============================] - 196s 530us/step - loss: 0.4657 - acc: 0.8575\n",
      "Epoch 25/30\n",
      "370379/370379 [==============================] - 187s 506us/step - loss: 0.4665 - acc: 0.8576\n",
      "Epoch 26/30\n",
      "370379/370379 [==============================] - 185s 499us/step - loss: 0.4628 - acc: 0.8594\n",
      "Epoch 27/30\n",
      "370379/370379 [==============================] - 180s 486us/step - loss: 0.4595 - acc: 0.8596\n",
      "Epoch 28/30\n",
      "370379/370379 [==============================] - 186s 502us/step - loss: 0.4590 - acc: 0.8600\n",
      "Epoch 29/30\n",
      "370379/370379 [==============================] - 173s 466us/step - loss: 0.4546 - acc: 0.8612\n",
      "Epoch 30/30\n",
      "370379/370379 [==============================] - 181s 490us/step - loss: 0.4538 - acc: 0.8612\n",
      "158735/158735 [==============================] - 36s 225us/step\n",
      "Loss: 0.39701959608926446\n",
      "Accuracy: 0.8782877122251527\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 30\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 128(relu) - 32(tanh) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "loss_method = 'sparse_categorical_crossentropy'\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(lr), \n",
    "              loss=loss_method,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с малым датасетом, `Adam` в данной задаче плохо работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> @chiselko6 </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
