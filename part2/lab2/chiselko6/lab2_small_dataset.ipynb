{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При чтении будем хранить данные в переменной `CACHE`, чтобы ускорить загрузку. В случае их обновления, достаточно вызвать `read(override=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_DATASET_DIR = '../../nmnist/notMNIST_small/'\n",
    "LARGE_DATASET_DIR = '../../nmnist/notMNIST_large/'\n",
    "CACHE = {}\n",
    "LABEL_MAP = {}\n",
    "INV_LABEL_MAP = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data_dir, override=False):\n",
    "    f_v = 0\n",
    "    global CACHE\n",
    "    if not CACHE.get(data_dir, []) or override:\n",
    "        CACHE[data_dir] = []\n",
    "        X, y = [], []\n",
    "        for f in tqdm(os.listdir(data_dir), desc='Letter'):\n",
    "            if not f.startswith('.'):\n",
    "                img_dir = os.path.join(data_dir, f)\n",
    "                for img in os.listdir(img_dir):\n",
    "                    img_path = os.path.join(img_dir, img)\n",
    "                    data = cv2.imread(img_path, 0)\n",
    "                    if data is None:\n",
    "                        continue\n",
    "                    X.append(data * 2 / 255 - 1)\n",
    "                    if LABEL_MAP.get(f) is None:\n",
    "                        LABEL_MAP[f] = f_v\n",
    "                        INV_LABEL_MAP[f_v] = f\n",
    "                        f_v += 1\n",
    "                    y.append(LABEL_MAP[f])\n",
    "        CACHE[data_dir].append(np.array(X))\n",
    "        CACHE[data_dir].append(np.array(y))\n",
    "    return CACHE[data_dir][0], CACHE[data_dir][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, verbose=False, override=False):\n",
    "    X, y = read(data_dir, override=override)\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    N = X.shape[0]\n",
    "    if verbose:\n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "        print(X[:5])\n",
    "        print(y[:5])\n",
    "        print(np.unique(y))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(data_dir, size=(0.7, 0.3), verbose=False, random_state=6, override=False):\n",
    "    X, y = shuffle(*get_data(data_dir, verbose=verbose, override=override), random_state=random_state)\n",
    "    assert abs(np.sum(size) - 1.0) < 0.001\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size[1], random_state=random_state)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d9a1a8e28042f796dacac2a2ac447c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Letter', max=11, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_split_data(SMALL_DATASET_DIR, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим 5 слоев с функциями активации `ReLU` и `softmax` на последнем слое, коэффициент обучения $0.001$, $100$ эпох:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)\n",
      "Learning rate: 0.001\n",
      "Epochs: 100\n",
      "\n",
      "Epoch 1/100\n",
      "13106/13106 [==============================] - 4s 295us/step - loss: 2.0085 - acc: 0.3497\n",
      "Epoch 2/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 1.4721 - acc: 0.6099\n",
      "Epoch 3/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 1.0691 - acc: 0.7716\n",
      "Epoch 4/100\n",
      "13106/13106 [==============================] - 2s 190us/step - loss: 0.8325 - acc: 0.8294\n",
      "Epoch 5/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.7102 - acc: 0.8438\n",
      "Epoch 6/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.6426 - acc: 0.8530\n",
      "Epoch 7/100\n",
      "13106/13106 [==============================] - 3s 221us/step - loss: 0.5988 - acc: 0.8564\n",
      "Epoch 8/100\n",
      "13106/13106 [==============================] - 3s 235us/step - loss: 0.5680 - acc: 0.8625\n",
      "Epoch 9/100\n",
      "13106/13106 [==============================] - 3s 215us/step - loss: 0.5451 - acc: 0.8653\n",
      "Epoch 10/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.5263 - acc: 0.8694\n",
      "Epoch 11/100\n",
      "13106/13106 [==============================] - 3s 230us/step - loss: 0.5102 - acc: 0.8732\n",
      "Epoch 12/100\n",
      "13106/13106 [==============================] - 3s 226us/step - loss: 0.4966 - acc: 0.8762\n",
      "Epoch 13/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.4847 - acc: 0.8767\n",
      "Epoch 14/100\n",
      "13106/13106 [==============================] - 3s 214us/step - loss: 0.4738 - acc: 0.8782\n",
      "Epoch 15/100\n",
      "13106/13106 [==============================] - 3s 216us/step - loss: 0.4637 - acc: 0.8807\n",
      "Epoch 16/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.4555 - acc: 0.8834\n",
      "Epoch 17/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.4475 - acc: 0.8843\n",
      "Epoch 18/100\n",
      "13106/13106 [==============================] - 3s 213us/step - loss: 0.4404 - acc: 0.8859\n",
      "Epoch 19/100\n",
      "13106/13106 [==============================] - 3s 249us/step - loss: 0.4332 - acc: 0.8868\n",
      "Epoch 20/100\n",
      "13106/13106 [==============================] - 3s 213us/step - loss: 0.4269 - acc: 0.8884\n",
      "Epoch 21/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.4204 - acc: 0.8905\n",
      "Epoch 22/100\n",
      "13106/13106 [==============================] - 3s 223us/step - loss: 0.4138 - acc: 0.8905\n",
      "Epoch 23/100\n",
      "13106/13106 [==============================] - 3s 228us/step - loss: 0.4094 - acc: 0.8933\n",
      "Epoch 24/100\n",
      "13106/13106 [==============================] - 3s 198us/step - loss: 0.4038 - acc: 0.8936\n",
      "Epoch 25/100\n",
      "13106/13106 [==============================] - 5s 399us/step - loss: 0.3985 - acc: 0.8952\n",
      "Epoch 26/100\n",
      "13106/13106 [==============================] - 3s 248us/step - loss: 0.3938 - acc: 0.8962\n",
      "Epoch 27/100\n",
      "13106/13106 [==============================] - 3s 232us/step - loss: 0.3898 - acc: 0.8991\n",
      "Epoch 28/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.3848 - acc: 0.8990\n",
      "Epoch 29/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.3797 - acc: 0.9015\n",
      "Epoch 30/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.3762 - acc: 0.8998\n",
      "Epoch 31/100\n",
      "13106/13106 [==============================] - 2s 190us/step - loss: 0.3726 - acc: 0.9013\n",
      "Epoch 32/100\n",
      "13106/13106 [==============================] - 2s 189us/step - loss: 0.3687 - acc: 0.9029\n",
      "Epoch 33/100\n",
      "13106/13106 [==============================] - 2s 189us/step - loss: 0.3639 - acc: 0.9036\n",
      "Epoch 34/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.3610 - acc: 0.9048\n",
      "Epoch 35/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.3577 - acc: 0.9049\n",
      "Epoch 36/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.3532 - acc: 0.9062\n",
      "Epoch 37/100\n",
      "13106/13106 [==============================] - 3s 219us/step - loss: 0.3503 - acc: 0.9074\n",
      "Epoch 38/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.3479 - acc: 0.9066\n",
      "Epoch 39/100\n",
      "13106/13106 [==============================] - 3s 216us/step - loss: 0.3442 - acc: 0.9082\n",
      "Epoch 40/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.3409 - acc: 0.9089\n",
      "Epoch 41/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.3382 - acc: 0.9092\n",
      "Epoch 42/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.3339 - acc: 0.9117\n",
      "Epoch 43/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.3309 - acc: 0.9116\n",
      "Epoch 44/100\n",
      "13106/13106 [==============================] - 3s 226us/step - loss: 0.3285 - acc: 0.9129\n",
      "Epoch 45/100\n",
      "13106/13106 [==============================] - 3s 224us/step - loss: 0.3253 - acc: 0.9113\n",
      "Epoch 46/100\n",
      "13106/13106 [==============================] - 3s 215us/step - loss: 0.3227 - acc: 0.9149\n",
      "Epoch 47/100\n",
      "13106/13106 [==============================] - 3s 245us/step - loss: 0.3195 - acc: 0.9134\n",
      "Epoch 48/100\n",
      "13106/13106 [==============================] - 3s 239us/step - loss: 0.3166 - acc: 0.9132\n",
      "Epoch 49/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.3132 - acc: 0.9145\n",
      "Epoch 50/100\n",
      "13106/13106 [==============================] - 3s 214us/step - loss: 0.3114 - acc: 0.9157\n",
      "Epoch 51/100\n",
      "13106/13106 [==============================] - 3s 225us/step - loss: 0.3089 - acc: 0.9164\n",
      "Epoch 52/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.3057 - acc: 0.9175\n",
      "Epoch 53/100\n",
      "13106/13106 [==============================] - 3s 262us/step - loss: 0.3024 - acc: 0.9174\n",
      "Epoch 54/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.3003 - acc: 0.9181\n",
      "Epoch 55/100\n",
      "13106/13106 [==============================] - 2s 186us/step - loss: 0.2974 - acc: 0.9187\n",
      "Epoch 56/100\n",
      "13106/13106 [==============================] - 2s 179us/step - loss: 0.2950 - acc: 0.9200\n",
      "Epoch 57/100\n",
      "13106/13106 [==============================] - 3s 251us/step - loss: 0.2931 - acc: 0.9204\n",
      "Epoch 58/100\n",
      "13106/13106 [==============================] - 2s 186us/step - loss: 0.2896 - acc: 0.9199\n",
      "Epoch 59/100\n",
      "13106/13106 [==============================] - 3s 211us/step - loss: 0.2881 - acc: 0.9202\n",
      "Epoch 60/100\n",
      "13106/13106 [==============================] - 3s 235us/step - loss: 0.2860 - acc: 0.9211\n",
      "Epoch 61/100\n",
      "13106/13106 [==============================] - 2s 178us/step - loss: 0.2833 - acc: 0.9222\n",
      "Epoch 62/100\n",
      "13106/13106 [==============================] - 2s 171us/step - loss: 0.2798 - acc: 0.9235\n",
      "Epoch 63/100\n",
      "13106/13106 [==============================] - 2s 171us/step - loss: 0.2788 - acc: 0.9232\n",
      "Epoch 64/100\n",
      "13106/13106 [==============================] - 2s 173us/step - loss: 0.2759 - acc: 0.9233\n",
      "Epoch 65/100\n",
      "13106/13106 [==============================] - 2s 184us/step - loss: 0.2737 - acc: 0.9261\n",
      "Epoch 66/100\n",
      "13106/13106 [==============================] - 3s 194us/step - loss: 0.2712 - acc: 0.9257\n",
      "Epoch 67/100\n",
      "13106/13106 [==============================] - 2s 170us/step - loss: 0.2690 - acc: 0.9245\n",
      "Epoch 68/100\n",
      "13106/13106 [==============================] - 2s 173us/step - loss: 0.2665 - acc: 0.9251\n",
      "Epoch 69/100\n",
      "13106/13106 [==============================] - 2s 182us/step - loss: 0.2640 - acc: 0.9271\n",
      "Epoch 70/100\n",
      "13106/13106 [==============================] - 2s 170us/step - loss: 0.2629 - acc: 0.9270\n",
      "Epoch 71/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.2601 - acc: 0.9283\n",
      "Epoch 72/100\n",
      "13106/13106 [==============================] - 4s 294us/step - loss: 0.2578 - acc: 0.9259 1s - loss: \n",
      "Epoch 73/100\n",
      "13106/13106 [==============================] - 3s 237us/step - loss: 0.2561 - acc: 0.9290\n",
      "Epoch 74/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.2537 - acc: 0.9292\n",
      "Epoch 75/100\n",
      "13106/13106 [==============================] - 3s 221us/step - loss: 0.2509 - acc: 0.9301\n",
      "Epoch 76/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.2492 - acc: 0.9319\n",
      "Epoch 77/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.2475 - acc: 0.9303\n",
      "Epoch 78/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.2453 - acc: 0.9331\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13106/13106 [==============================] - 3s 216us/step - loss: 0.2432 - acc: 0.9326\n",
      "Epoch 80/100\n",
      "13106/13106 [==============================] - 3s 198us/step - loss: 0.2411 - acc: 0.9313\n",
      "Epoch 81/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.2394 - acc: 0.9321\n",
      "Epoch 82/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.2377 - acc: 0.9328\n",
      "Epoch 83/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.2352 - acc: 0.9341\n",
      "Epoch 84/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.2329 - acc: 0.9342\n",
      "Epoch 85/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.2312 - acc: 0.9348\n",
      "Epoch 86/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.2293 - acc: 0.9347\n",
      "Epoch 87/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.2268 - acc: 0.9363\n",
      "Epoch 88/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.2249 - acc: 0.9361\n",
      "Epoch 89/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.2240 - acc: 0.9373\n",
      "Epoch 90/100\n",
      "13106/13106 [==============================] - 3s 211us/step - loss: 0.2212 - acc: 0.9377\n",
      "Epoch 91/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.2195 - acc: 0.9386\n",
      "Epoch 92/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.2176 - acc: 0.9393\n",
      "Epoch 93/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.2164 - acc: 0.9384\n",
      "Epoch 94/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.2137 - acc: 0.9409\n",
      "Epoch 95/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.2119 - acc: 0.9394\n",
      "Epoch 96/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.2101 - acc: 0.9397\n",
      "Epoch 97/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.2084 - acc: 0.9421\n",
      "Epoch 98/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.2063 - acc: 0.9411\n",
      "Epoch 99/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.2046 - acc: 0.9423\n",
      "Epoch 100/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.2028 - acc: 0.9427\n",
      "5618/5618 [==============================] - 1s 175us/step\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Loss**: 0.3476183395700157"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy**: 0.9013883944464223"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 100\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(lr), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "printmd(f'**Loss**: {loss}')\n",
    "printmd(f'**Accuracy**: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим коэффициент обучения на больший `lr = 0.1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)\n",
      "Learning rate: 0.1\n",
      "Epochs: 100\n",
      "\n",
      "Epoch 1/100\n",
      "13106/13106 [==============================] - 5s 366us/step - loss: 0.7723 - acc: 0.7586\n",
      "Epoch 2/100\n",
      "13106/13106 [==============================] - 3s 224us/step - loss: 0.4170 - acc: 0.8749\n",
      "Epoch 3/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.3510 - acc: 0.8910\n",
      "Epoch 4/100\n",
      "13106/13106 [==============================] - 3s 211us/step - loss: 0.3143 - acc: 0.8997\n",
      "Epoch 5/100\n",
      "13106/13106 [==============================] - 3s 222us/step - loss: 0.2814 - acc: 0.9117\n",
      "Epoch 6/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.2575 - acc: 0.9176\n",
      "Epoch 7/100\n",
      "13106/13106 [==============================] - 3s 225us/step - loss: 0.2320 - acc: 0.9265\n",
      "Epoch 8/100\n",
      "13106/13106 [==============================] - 3s 249us/step - loss: 0.2189 - acc: 0.9283\n",
      "Epoch 9/100\n",
      "13106/13106 [==============================] - 3s 241us/step - loss: 0.2087 - acc: 0.9307\n",
      "Epoch 10/100\n",
      "13106/13106 [==============================] - 3s 242us/step - loss: 0.1829 - acc: 0.9401\n",
      "Epoch 11/100\n",
      "13106/13106 [==============================] - 3s 235us/step - loss: 0.1727 - acc: 0.9453\n",
      "Epoch 12/100\n",
      "13106/13106 [==============================] - 3s 221us/step - loss: 0.1624 - acc: 0.9458\n",
      "Epoch 13/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.1514 - acc: 0.9515\n",
      "Epoch 14/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.1350 - acc: 0.9545\n",
      "Epoch 15/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.1391 - acc: 0.9551\n",
      "Epoch 16/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.1463 - acc: 0.9532\n",
      "Epoch 17/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.1173 - acc: 0.9602\n",
      "Epoch 18/100\n",
      "13106/13106 [==============================] - 3s 196us/step - loss: 0.1185 - acc: 0.9615\n",
      "Epoch 19/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.1130 - acc: 0.9640\n",
      "Epoch 20/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.1072 - acc: 0.9648\n",
      "Epoch 21/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0863 - acc: 0.9716\n",
      "Epoch 22/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.1007 - acc: 0.9661\n",
      "Epoch 23/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.0855 - acc: 0.9724\n",
      "Epoch 24/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0746 - acc: 0.9754\n",
      "Epoch 25/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0687 - acc: 0.9779\n",
      "Epoch 26/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.0698 - acc: 0.9786\n",
      "Epoch 27/100\n",
      "13106/13106 [==============================] - 4s 273us/step - loss: 0.0823 - acc: 0.9760\n",
      "Epoch 28/100\n",
      "13106/13106 [==============================] - 4s 270us/step - loss: 0.0679 - acc: 0.9779\n",
      "Epoch 29/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.0589 - acc: 0.9808\n",
      "Epoch 30/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0567 - acc: 0.9827\n",
      "Epoch 31/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0534 - acc: 0.9834\n",
      "Epoch 32/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0723 - acc: 0.9797\n",
      "Epoch 33/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.0628 - acc: 0.9796\n",
      "Epoch 34/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.0521 - acc: 0.9831\n",
      "Epoch 35/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.0439 - acc: 0.9861\n",
      "Epoch 36/100\n",
      "13106/13106 [==============================] - 3s 227us/step - loss: 0.0526 - acc: 0.9843\n",
      "Epoch 37/100\n",
      "13106/13106 [==============================] - 3s 218us/step - loss: 0.0759 - acc: 0.9796\n",
      "Epoch 38/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.0360 - acc: 0.9895\n",
      "Epoch 39/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0457 - acc: 0.9864\n",
      "Epoch 40/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.0272 - acc: 0.9914\n",
      "Epoch 41/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.0476 - acc: 0.9866\n",
      "Epoch 42/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0303 - acc: 0.9901\n",
      "Epoch 43/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0662 - acc: 0.9822\n",
      "Epoch 44/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.0353 - acc: 0.9895\n",
      "Epoch 45/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.0338 - acc: 0.9895\n",
      "Epoch 46/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.0514 - acc: 0.9839\n",
      "Epoch 47/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.0323 - acc: 0.9913\n",
      "Epoch 48/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.0332 - acc: 0.9901\n",
      "Epoch 49/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0406 - acc: 0.9881\n",
      "Epoch 50/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.0269 - acc: 0.9908\n",
      "Epoch 51/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.0277 - acc: 0.9916\n",
      "Epoch 52/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.0236 - acc: 0.9934\n",
      "Epoch 53/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0171 - acc: 0.9941\n",
      "Epoch 54/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.0296 - acc: 0.9914\n",
      "Epoch 55/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.0362 - acc: 0.9904\n",
      "Epoch 56/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.0207 - acc: 0.9931\n",
      "Epoch 57/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0206 - acc: 0.9934\n",
      "Epoch 58/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0253 - acc: 0.9922\n",
      "Epoch 59/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.0199 - acc: 0.9947\n",
      "Epoch 60/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0303 - acc: 0.9908\n",
      "Epoch 61/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0273 - acc: 0.9936\n",
      "Epoch 62/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0265 - acc: 0.9912\n",
      "Epoch 63/100\n",
      "13106/13106 [==============================] - 3s 198us/step - loss: 0.0334 - acc: 0.9898\n",
      "Epoch 64/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0335 - acc: 0.9893\n",
      "Epoch 65/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0099 - acc: 0.9964\n",
      "Epoch 66/100\n",
      "13106/13106 [==============================] - 3s 226us/step - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 67/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.0073 - acc: 0.9978\n",
      "Epoch 68/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0109 - acc: 0.9965\n",
      "Epoch 69/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.0103 - acc: 0.9964\n",
      "Epoch 70/100\n",
      "13106/13106 [==============================] - 4s 313us/step - loss: 0.0198 - acc: 0.9939\n",
      "Epoch 71/100\n",
      "13106/13106 [==============================] - 4s 335us/step - loss: 0.0118 - acc: 0.9956\n",
      "Epoch 72/100\n",
      "13106/13106 [==============================] - 3s 230us/step - loss: 0.0236 - acc: 0.9934\n",
      "Epoch 73/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.0452 - acc: 0.9873\n",
      "Epoch 74/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 75/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.0127 - acc: 0.9959\n",
      "Epoch 76/100\n",
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.0154 - acc: 0.9957\n",
      "Epoch 77/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 78/100\n",
      "13106/13106 [==============================] - 3s 194us/step - loss: 0.0118 - acc: 0.9957\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.0103 - acc: 0.9974\n",
      "Epoch 80/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.0052 - acc: 0.9986\n",
      "Epoch 81/100\n",
      "13106/13106 [==============================] - 3s 198us/step - loss: 0.0062 - acc: 0.9979\n",
      "Epoch 82/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.0080 - acc: 0.9978\n",
      "Epoch 83/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.0059 - acc: 0.9982\n",
      "Epoch 84/100\n",
      "13106/13106 [==============================] - 3s 194us/step - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 85/100\n",
      "13106/13106 [==============================] - 3s 198us/step - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 86/100\n",
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 87/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.0014 - acc: 0.9995\n",
      "Epoch 88/100\n",
      "13106/13106 [==============================] - 3s 194us/step - loss: 0.0017 - acc: 0.9994\n",
      "Epoch 89/100\n",
      "13106/13106 [==============================] - 3s 196us/step - loss: 0.0021 - acc: 0.9992\n",
      "Epoch 90/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 91/100\n",
      "13106/13106 [==============================] - 3s 267us/step - loss: 0.0040 - acc: 0.9987\n",
      "Epoch 92/100\n",
      "13106/13106 [==============================] - 3s 211us/step - loss: 0.0047 - acc: 0.9986\n",
      "Epoch 93/100\n",
      "13106/13106 [==============================] - 2s 167us/step - loss: 0.0057 - acc: 0.9987\n",
      "Epoch 94/100\n",
      "13106/13106 [==============================] - 2s 171us/step - loss: 0.0022 - acc: 0.9992\n",
      "Epoch 95/100\n",
      "13106/13106 [==============================] - 2s 169us/step - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 96/100\n",
      "13106/13106 [==============================] - 2s 171us/step - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 97/100\n",
      "13106/13106 [==============================] - 2s 172us/step - loss: 0.0558 - acc: 0.9857\n",
      "Epoch 98/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.0148 - acc: 0.9950\n",
      "Epoch 99/100\n",
      "13106/13106 [==============================] - 2s 180us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 100/100\n",
      "13106/13106 [==============================] - 2s 172us/step - loss: 0.0075 - acc: 0.9978\n",
      "5618/5618 [==============================] - 1s 158us/step\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Loss**: 0.5417178698837813"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy**: 0.9229263082947669"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "epochs = 100\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(lr), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "printmd(f'**Loss**: {loss}')\n",
    "printmd(f'**Accuracy**: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность увеличилась, попробуем найти оптимальный коэффициент обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)\n",
      "Learning rate: 0.2\n",
      "Epochs: 100\n",
      "\n",
      "Epoch 1/100\n",
      "13106/13106 [==============================] - 4s 321us/step - loss: 1.2485 - acc: 0.6035\n",
      "Epoch 2/100\n",
      "13106/13106 [==============================] - 2s 189us/step - loss: 0.4966 - acc: 0.8528\n",
      "Epoch 3/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.4104 - acc: 0.8766\n",
      "Epoch 4/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.3694 - acc: 0.8875\n",
      "Epoch 5/100\n",
      "13106/13106 [==============================] - 3s 221us/step - loss: 0.3338 - acc: 0.8970\n",
      "Epoch 6/100\n",
      "13106/13106 [==============================] - 3s 227us/step - loss: 0.3085 - acc: 0.9042\n",
      "Epoch 7/100\n",
      "13106/13106 [==============================] - 3s 221us/step - loss: 0.2867 - acc: 0.9109\n",
      "Epoch 8/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.2640 - acc: 0.9152\n",
      "Epoch 9/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.2793 - acc: 0.9131\n",
      "Epoch 10/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.2607 - acc: 0.9181\n",
      "Epoch 11/100\n",
      "13106/13106 [==============================] - 3s 217us/step - loss: 0.2499 - acc: 0.9213\n",
      "Epoch 12/100\n",
      "13106/13106 [==============================] - 3s 218us/step - loss: 0.2164 - acc: 0.9295\n",
      "Epoch 13/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.2076 - acc: 0.9335\n",
      "Epoch 14/100\n",
      "13106/13106 [==============================] - 3s 211us/step - loss: 0.2176 - acc: 0.9348\n",
      "Epoch 15/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.2100 - acc: 0.9341\n",
      "Epoch 16/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.1807 - acc: 0.9416\n",
      "Epoch 17/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.1792 - acc: 0.9408\n",
      "Epoch 18/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.1728 - acc: 0.9416\n",
      "Epoch 19/100\n",
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.1551 - acc: 0.9490\n",
      "Epoch 20/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.1679 - acc: 0.9467\n",
      "Epoch 21/100\n",
      "13106/13106 [==============================] - 3s 224us/step - loss: 0.1606 - acc: 0.9476\n",
      "Epoch 22/100\n",
      "13106/13106 [==============================] - 3s 215us/step - loss: 0.1943 - acc: 0.9422\n",
      "Epoch 23/100\n",
      "13106/13106 [==============================] - 3s 220us/step - loss: 0.1326 - acc: 0.9560\n",
      "Epoch 24/100\n",
      "13106/13106 [==============================] - 3s 220us/step - loss: 0.1504 - acc: 0.9499\n",
      "Epoch 25/100\n",
      "13106/13106 [==============================] - 3s 218us/step - loss: 0.1411 - acc: 0.9530\n",
      "Epoch 26/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.1362 - acc: 0.9550\n",
      "Epoch 27/100\n",
      "13106/13106 [==============================] - 3s 214us/step - loss: 0.1162 - acc: 0.9614\n",
      "Epoch 28/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.1199 - acc: 0.9618\n",
      "Epoch 29/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.1175 - acc: 0.9641\n",
      "Epoch 30/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.1004 - acc: 0.9666\n",
      "Epoch 31/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.1092 - acc: 0.9659\n",
      "Epoch 32/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.1035 - acc: 0.9672\n",
      "Epoch 33/100\n",
      "13106/13106 [==============================] - 3s 221us/step - loss: 0.1037 - acc: 0.9664\n",
      "Epoch 34/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.0816 - acc: 0.9722\n",
      "Epoch 35/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.0868 - acc: 0.9730\n",
      "Epoch 36/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0977 - acc: 0.9681\n",
      "Epoch 37/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0979 - acc: 0.9702\n",
      "Epoch 38/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.0961 - acc: 0.9716\n",
      "Epoch 39/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0771 - acc: 0.9757\n",
      "Epoch 40/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.0914 - acc: 0.9703\n",
      "Epoch 41/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.1011 - acc: 0.9709\n",
      "Epoch 42/100\n",
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.0798 - acc: 0.9745\n",
      "Epoch 43/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.0761 - acc: 0.9753\n",
      "Epoch 44/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0528 - acc: 0.9824\n",
      "Epoch 45/100\n",
      "13106/13106 [==============================] - 3s 228us/step - loss: 0.1139 - acc: 0.9686\n",
      "Epoch 46/100\n",
      "13106/13106 [==============================] - 3s 237us/step - loss: 0.0758 - acc: 0.9767\n",
      "Epoch 47/100\n",
      "13106/13106 [==============================] - 2s 185us/step - loss: 0.0659 - acc: 0.9785\n",
      "Epoch 48/100\n",
      "13106/13106 [==============================] - 2s 186us/step - loss: 0.0659 - acc: 0.9789\n",
      "Epoch 49/100\n",
      "13106/13106 [==============================] - 2s 181us/step - loss: 0.0641 - acc: 0.9786\n",
      "Epoch 50/100\n",
      "13106/13106 [==============================] - 3s 238us/step - loss: 0.0474 - acc: 0.9846\n",
      "Epoch 51/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.1047 - acc: 0.9701\n",
      "Epoch 52/100\n",
      "13106/13106 [==============================] - 4s 270us/step - loss: 0.0618 - acc: 0.9815\n",
      "Epoch 53/100\n",
      "13106/13106 [==============================] - 3s 256us/step - loss: 0.0683 - acc: 0.9790\n",
      "Epoch 54/100\n",
      "13106/13106 [==============================] - 4s 338us/step - loss: 0.0436 - acc: 0.9871\n",
      "Epoch 55/100\n",
      "13106/13106 [==============================] - 2s 189us/step - loss: 0.0669 - acc: 0.9805\n",
      "Epoch 56/100\n",
      "13106/13106 [==============================] - 2s 181us/step - loss: 0.0445 - acc: 0.9867\n",
      "Epoch 57/100\n",
      "13106/13106 [==============================] - 2s 178us/step - loss: 0.0590 - acc: 0.9831\n",
      "Epoch 58/100\n",
      "13106/13106 [==============================] - 3s 236us/step - loss: 0.0465 - acc: 0.9856\n",
      "Epoch 59/100\n",
      "13106/13106 [==============================] - 3s 219us/step - loss: 0.0616 - acc: 0.9810\n",
      "Epoch 60/100\n",
      "13106/13106 [==============================] - 3s 229us/step - loss: 0.0421 - acc: 0.9860\n",
      "Epoch 61/100\n",
      "13106/13106 [==============================] - 3s 213us/step - loss: 0.0451 - acc: 0.9866\n",
      "Epoch 62/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.0675 - acc: 0.9792\n",
      "Epoch 63/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0566 - acc: 0.9823\n",
      "Epoch 64/100\n",
      "13106/13106 [==============================] - 3s 210us/step - loss: 0.0492 - acc: 0.9841\n",
      "Epoch 65/100\n",
      "13106/13106 [==============================] - 3s 217us/step - loss: 0.0413 - acc: 0.9868\n",
      "Epoch 66/100\n",
      "13106/13106 [==============================] - 3s 229us/step - loss: 0.0478 - acc: 0.9859\n",
      "Epoch 67/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.0539 - acc: 0.9840\n",
      "Epoch 68/100\n",
      "13106/13106 [==============================] - 3s 226us/step - loss: 0.0351 - acc: 0.9894\n",
      "Epoch 69/100\n",
      "13106/13106 [==============================] - 3s 215us/step - loss: 0.0319 - acc: 0.9905\n",
      "Epoch 70/100\n",
      "13106/13106 [==============================] - 3s 213us/step - loss: 0.0567 - acc: 0.9853\n",
      "Epoch 71/100\n",
      "13106/13106 [==============================] - 3s 219us/step - loss: 0.0215 - acc: 0.9937\n",
      "Epoch 72/100\n",
      "13106/13106 [==============================] - 3s 224us/step - loss: 0.0265 - acc: 0.9913\n",
      "Epoch 73/100\n",
      "13106/13106 [==============================] - ETA: 0s - loss: 0.0428 - acc: 0.988 - 3s 211us/step - loss: 0.0432 - acc: 0.9886\n",
      "Epoch 74/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.0510 - acc: 0.9851\n",
      "Epoch 75/100\n",
      "13106/13106 [==============================] - 3s 238us/step - loss: 0.0514 - acc: 0.9846\n",
      "Epoch 76/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0963 - acc: 0.9796\n",
      "Epoch 77/100\n",
      "13106/13106 [==============================] - 3s 214us/step - loss: 0.0481 - acc: 0.9858\n",
      "Epoch 78/100\n",
      "13106/13106 [==============================] - 3s 228us/step - loss: 0.0339 - acc: 0.9897 1s - lo\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13106/13106 [==============================] - 3s 205us/step - loss: 0.0542 - acc: 0.9857\n",
      "Epoch 80/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0348 - acc: 0.9899\n",
      "Epoch 81/100\n",
      "13106/13106 [==============================] - 3s 196us/step - loss: 0.0236 - acc: 0.9933\n",
      "Epoch 82/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0234 - acc: 0.9928\n",
      "Epoch 83/100\n",
      "13106/13106 [==============================] - 3s 219us/step - loss: 0.0295 - acc: 0.9914\n",
      "Epoch 84/100\n",
      "13106/13106 [==============================] - 3s 214us/step - loss: 0.0628 - acc: 0.9854\n",
      "Epoch 85/100\n",
      "13106/13106 [==============================] - 3s 198us/step - loss: 0.0466 - acc: 0.9871\n",
      "Epoch 86/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.0467 - acc: 0.9875\n",
      "Epoch 87/100\n",
      "13106/13106 [==============================] - 3s 196us/step - loss: 0.0324 - acc: 0.9916\n",
      "Epoch 88/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.0197 - acc: 0.9940\n",
      "Epoch 89/100\n",
      "13106/13106 [==============================] - 2s 189us/step - loss: 0.0326 - acc: 0.9918\n",
      "Epoch 90/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.0389 - acc: 0.9893\n",
      "Epoch 91/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.0231 - acc: 0.9924\n",
      "Epoch 92/100\n",
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.0386 - acc: 0.9895\n",
      "Epoch 93/100\n",
      "13106/13106 [==============================] - 3s 194us/step - loss: 0.0427 - acc: 0.9879\n",
      "Epoch 94/100\n",
      "13106/13106 [==============================] - 3s 216us/step - loss: 0.0398 - acc: 0.9890\n",
      "Epoch 95/100\n",
      "13106/13106 [==============================] - 3s 218us/step - loss: 0.0131 - acc: 0.9960\n",
      "Epoch 96/100\n",
      "13106/13106 [==============================] - 3s 194us/step - loss: 0.0191 - acc: 0.9952\n",
      "Epoch 97/100\n",
      "13106/13106 [==============================] - 2s 190us/step - loss: 0.0316 - acc: 0.9902\n",
      "Epoch 98/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.0294 - acc: 0.9920\n",
      "Epoch 99/100\n",
      "13106/13106 [==============================] - 3s 218us/step - loss: 0.0286 - acc: 0.9932\n",
      "Epoch 100/100\n",
      "13106/13106 [==============================] - 3s 194us/step - loss: 0.0154 - acc: 0.9957\n",
      "5618/5618 [==============================] - 1s 179us/step\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Loss**: 0.5655547246731695"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy**: 0.9213243147027412"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.2\n",
    "epochs = 100\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 256(relu) - 64(relu) - 32(relu) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(lr), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "printmd(f'**Loss**: {loss}')\n",
    "printmd(f'**Accuracy**: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, точность упала. Поэтому экспериментально будем считать, что коэффициент обучения, увеличение которого ухудшает точность, равен `lr_opt = 0.1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее попробуем применить другие функции активации, например `tanh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(tanh) - 128(tanh) - 32(tanh) - 10(softmax)\n",
      "Learning rate: 0.1\n",
      "Epochs: 100\n",
      "\n",
      "Epoch 1/100\n",
      "13106/13106 [==============================] - 4s 329us/step - loss: 0.6883 - acc: 0.8031\n",
      "Epoch 2/100\n",
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.4123 - acc: 0.8810\n",
      "Epoch 3/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.3490 - acc: 0.8944\n",
      "Epoch 4/100\n",
      "13106/13106 [==============================] - 4s 341us/step - loss: 0.3126 - acc: 0.9062 1s\n",
      "Epoch 5/100\n",
      "13106/13106 [==============================] - 3s 230us/step - loss: 0.2793 - acc: 0.9161\n",
      "Epoch 6/100\n",
      "13106/13106 [==============================] - 3s 222us/step - loss: 0.2563 - acc: 0.9212\n",
      "Epoch 7/100\n",
      "13106/13106 [==============================] - 3s 220us/step - loss: 0.2345 - acc: 0.9265\n",
      "Epoch 8/100\n",
      "13106/13106 [==============================] - 3s 214us/step - loss: 0.2161 - acc: 0.9337\n",
      "Epoch 9/100\n",
      "13106/13106 [==============================] - 4s 305us/step - loss: 0.1937 - acc: 0.9409\n",
      "Epoch 10/100\n",
      "13106/13106 [==============================] - 2s 177us/step - loss: 0.1807 - acc: 0.9445\n",
      "Epoch 11/100\n",
      "13106/13106 [==============================] - 2s 178us/step - loss: 0.1588 - acc: 0.9512\n",
      "Epoch 12/100\n",
      "13106/13106 [==============================] - 3s 191us/step - loss: 0.1538 - acc: 0.9530\n",
      "Epoch 13/100\n",
      "13106/13106 [==============================] - 3s 213us/step - loss: 0.1421 - acc: 0.9552\n",
      "Epoch 14/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.1251 - acc: 0.9608\n",
      "Epoch 15/100\n",
      "13106/13106 [==============================] - 3s 223us/step - loss: 0.1132 - acc: 0.9651\n",
      "Epoch 16/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.1027 - acc: 0.9673\n",
      "Epoch 17/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.0934 - acc: 0.9715\n",
      "Epoch 18/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0820 - acc: 0.9755\n",
      "Epoch 19/100\n",
      "13106/13106 [==============================] - 3s 195us/step - loss: 0.0826 - acc: 0.9757\n",
      "Epoch 20/100\n",
      "13106/13106 [==============================] - 3s 202us/step - loss: 0.0629 - acc: 0.9823\n",
      "Epoch 21/100\n",
      "13106/13106 [==============================] - 3s 204us/step - loss: 0.0554 - acc: 0.9834\n",
      "Epoch 22/100\n",
      "13106/13106 [==============================] - 3s 207us/step - loss: 0.0533 - acc: 0.9854\n",
      "Epoch 23/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0753 - acc: 0.9773\n",
      "Epoch 24/100\n",
      "13106/13106 [==============================] - 3s 218us/step - loss: 0.0593 - acc: 0.9823\n",
      "Epoch 25/100\n",
      "13106/13106 [==============================] - 3s 222us/step - loss: 0.0435 - acc: 0.9873\n",
      "Epoch 26/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.0475 - acc: 0.9871\n",
      "Epoch 27/100\n",
      "13106/13106 [==============================] - 3s 196us/step - loss: 0.0321 - acc: 0.9921\n",
      "Epoch 28/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0328 - acc: 0.9912\n",
      "Epoch 29/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0257 - acc: 0.9943\n",
      "Epoch 30/100\n",
      "13106/13106 [==============================] - 3s 220us/step - loss: 0.0216 - acc: 0.9953\n",
      "Epoch 31/100\n",
      "13106/13106 [==============================] - 3s 211us/step - loss: 0.0173 - acc: 0.9963\n",
      "Epoch 32/100\n",
      "13106/13106 [==============================] - 4s 268us/step - loss: 0.0221 - acc: 0.9940\n",
      "Epoch 33/100\n",
      "13106/13106 [==============================] - 3s 247us/step - loss: 0.0170 - acc: 0.9962\n",
      "Epoch 34/100\n",
      "13106/13106 [==============================] - 3s 229us/step - loss: 0.0153 - acc: 0.9968\n",
      "Epoch 35/100\n",
      "13106/13106 [==============================] - 3s 200us/step - loss: 0.0258 - acc: 0.9938\n",
      "Epoch 36/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.0145 - acc: 0.9969\n",
      "Epoch 37/100\n",
      "13106/13106 [==============================] - 3s 218us/step - loss: 0.0283 - acc: 0.9924\n",
      "Epoch 38/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0123 - acc: 0.9972\n",
      "Epoch 39/100\n",
      "13106/13106 [==============================] - 3s 206us/step - loss: 0.0076 - acc: 0.9984\n",
      "Epoch 40/100\n",
      "13106/13106 [==============================] - 3s 197us/step - loss: 0.0067 - acc: 0.9989\n",
      "Epoch 41/100\n",
      "13106/13106 [==============================] - 3s 211us/step - loss: 0.0088 - acc: 0.9980\n",
      "Epoch 42/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.0266 - acc: 0.9933\n",
      "Epoch 43/100\n",
      "13106/13106 [==============================] - 3s 222us/step - loss: 0.0091 - acc: 0.9982\n",
      "Epoch 44/100\n",
      "13106/13106 [==============================] - 3s 223us/step - loss: 0.0093 - acc: 0.9978\n",
      "Epoch 45/100\n",
      "13106/13106 [==============================] - 3s 201us/step - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 46/100\n",
      "13106/13106 [==============================] - 3s 215us/step - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 47/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 48/100\n",
      "13106/13106 [==============================] - 3s 229us/step - loss: 0.0045 - acc: 0.9990\n",
      "Epoch 49/100\n",
      "13106/13106 [==============================] - 3s 248us/step - loss: 0.0056 - acc: 0.9989\n",
      "Epoch 50/100\n",
      "13106/13106 [==============================] - 3s 217us/step - loss: 0.0986 - acc: 0.9695\n",
      "Epoch 51/100\n",
      "13106/13106 [==============================] - 2s 172us/step - loss: 0.0476 - acc: 0.9856\n",
      "Epoch 52/100\n",
      "13106/13106 [==============================] - 2s 171us/step - loss: 0.0203 - acc: 0.9941\n",
      "Epoch 53/100\n",
      "13106/13106 [==============================] - 2s 170us/step - loss: 0.0068 - acc: 0.9988\n",
      "Epoch 54/100\n",
      "13106/13106 [==============================] - 2s 170us/step - loss: 0.0095 - acc: 0.9976\n",
      "Epoch 55/100\n",
      "13106/13106 [==============================] - 3s 227us/step - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 56/100\n",
      "13106/13106 [==============================] - 3s 226us/step - loss: 0.0040 - acc: 0.9992\n",
      "Epoch 57/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0294 - acc: 0.9931\n",
      "Epoch 58/100\n",
      "13106/13106 [==============================] - 3s 208us/step - loss: 0.0114 - acc: 0.9973\n",
      "Epoch 59/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.0087 - acc: 0.9982\n",
      "Epoch 60/100\n",
      "13106/13106 [==============================] - 3s 212us/step - loss: 0.0038 - acc: 0.9994\n",
      "Epoch 61/100\n",
      "13106/13106 [==============================] - 2s 174us/step - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 62/100\n",
      "13106/13106 [==============================] - 2s 183us/step - loss: 0.0044 - acc: 0.9986\n",
      "Epoch 63/100\n",
      "13106/13106 [==============================] - 3s 191us/step - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 64/100\n",
      "13106/13106 [==============================] - 2s 186us/step - loss: 0.0028 - acc: 0.9995\n",
      "Epoch 65/100\n",
      "13106/13106 [==============================] - 2s 186us/step - loss: 0.0072 - acc: 0.9979\n",
      "Epoch 66/100\n",
      "13106/13106 [==============================] - 2s 176us/step - loss: 0.0062 - acc: 0.9986\n",
      "Epoch 67/100\n",
      "13106/13106 [==============================] - 2s 172us/step - loss: 0.0085 - acc: 0.9979\n",
      "Epoch 68/100\n",
      "13106/13106 [==============================] - 2s 172us/step - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 69/100\n",
      "13106/13106 [==============================] - 2s 171us/step - loss: 0.0026 - acc: 0.9995\n",
      "Epoch 70/100\n",
      "13106/13106 [==============================] - 2s 174us/step - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 71/100\n",
      "13106/13106 [==============================] - 2s 181us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 72/100\n",
      "13106/13106 [==============================] - 2s 181us/step - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 73/100\n",
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 74/100\n",
      "13106/13106 [==============================] - 3s 222us/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 75/100\n",
      "13106/13106 [==============================] - 3s 243us/step - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 76/100\n",
      "13106/13106 [==============================] - 4s 278us/step - loss: 0.0052 - acc: 0.9984\n",
      "Epoch 77/100\n",
      "13106/13106 [==============================] - 3s 219us/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 78/100\n",
      "13106/13106 [==============================] - 3s 209us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13106/13106 [==============================] - 3s 231us/step - loss: 0.0226 - acc: 0.9938\n",
      "Epoch 80/100\n",
      "13106/13106 [==============================] - 3s 203us/step - loss: 0.0274 - acc: 0.9918\n",
      "Epoch 81/100\n",
      "13106/13106 [==============================] - 2s 181us/step - loss: 0.0039 - acc: 0.9992\n",
      "Epoch 82/100\n",
      "13106/13106 [==============================] - 2s 184us/step - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 83/100\n",
      "13106/13106 [==============================] - 3s 235us/step - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 84/100\n",
      "13106/13106 [==============================] - 3s 248us/step - loss: 0.0026 - acc: 0.9992\n",
      "Epoch 85/100\n",
      "13106/13106 [==============================] - 2s 178us/step - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 86/100\n",
      "13106/13106 [==============================] - 2s 176us/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 87/100\n",
      "13106/13106 [==============================] - 2s 177us/step - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 88/100\n",
      "13106/13106 [==============================] - 2s 176us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 89/100\n",
      "13106/13106 [==============================] - 2s 175us/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 90/100\n",
      "13106/13106 [==============================] - 3s 199us/step - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 91/100\n",
      "13106/13106 [==============================] - 2s 186us/step - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 92/100\n",
      "13106/13106 [==============================] - 2s 182us/step - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 93/100\n",
      "13106/13106 [==============================] - 2s 176us/step - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 94/100\n",
      "13106/13106 [==============================] - 2s 180us/step - loss: 0.0014 - acc: 0.9995\n",
      "Epoch 95/100\n",
      "13106/13106 [==============================] - 2s 177us/step - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 96/100\n",
      "13106/13106 [==============================] - 2s 183us/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 97/100\n",
      "13106/13106 [==============================] - 2s 178us/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 98/100\n",
      "13106/13106 [==============================] - 2s 174us/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 99/100\n",
      "13106/13106 [==============================] - 3s 192us/step - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 100/100\n",
      "13106/13106 [==============================] - 3s 193us/step - loss: 0.0012 - acc: 0.9996\n",
      "5618/5618 [==============================] - 1s 231us/step\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Loss**: 0.4921583931814002"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy**: 0.9195443218227127"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "epochs = 100\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(tanh) - 128(tanh) - 32(tanh) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(128, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(32, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(lr), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "printmd(f'**Loss**: {loss}')\n",
    "printmd(f'**Accuracy**: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом результаты не улучшились"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добавить dropout (используем небольшой коэффициент, как рекомендуется здесь: https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "\n",
    "```Generally, use a small dropout value of 20%-50% of neurons with 20% providing a good starting point. A probability too low has minimal effect and a value too high results in under-learning by the network.```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 128(relu) - 32(tanh) - 10(softmax)\n",
      "Learning rate: 0.1\n",
      "Epochs: 100\n",
      "\n",
      "Epoch 1/100\n",
      "13106/13106 [==============================] - 5s 387us/step - loss: 0.8286 - acc: 0.7500\n",
      "Epoch 2/100\n",
      "13106/13106 [==============================] - 5s 381us/step - loss: 0.4943 - acc: 0.8556\n",
      "Epoch 3/100\n",
      "13106/13106 [==============================] - 4s 290us/step - loss: 0.4319 - acc: 0.8705\n",
      "Epoch 4/100\n",
      "13106/13106 [==============================] - 4s 286us/step - loss: 0.3848 - acc: 0.8855\n",
      "Epoch 5/100\n",
      "13106/13106 [==============================] - 4s 276us/step - loss: 0.3761 - acc: 0.8862\n",
      "Epoch 6/100\n",
      "13106/13106 [==============================] - 4s 271us/step - loss: 0.3491 - acc: 0.8958\n",
      "Epoch 7/100\n",
      "13106/13106 [==============================] - 4s 280us/step - loss: 0.3239 - acc: 0.9006\n",
      "Epoch 8/100\n",
      "13106/13106 [==============================] - 3s 261us/step - loss: 0.3128 - acc: 0.9059\n",
      "Epoch 9/100\n",
      "13106/13106 [==============================] - 3s 251us/step - loss: 0.3061 - acc: 0.9067\n",
      "Epoch 10/100\n",
      "13106/13106 [==============================] - 3s 255us/step - loss: 0.2920 - acc: 0.9100\n",
      "Epoch 11/100\n",
      "13106/13106 [==============================] - 3s 257us/step - loss: 0.2806 - acc: 0.9109\n",
      "Epoch 12/100\n",
      "13106/13106 [==============================] - 3s 254us/step - loss: 0.2666 - acc: 0.9148\n",
      "Epoch 13/100\n",
      "13106/13106 [==============================] - 3s 262us/step - loss: 0.2657 - acc: 0.9170\n",
      "Epoch 14/100\n",
      "13106/13106 [==============================] - 4s 284us/step - loss: 0.2577 - acc: 0.9186\n",
      "Epoch 15/100\n",
      "13106/13106 [==============================] - 3s 266us/step - loss: 0.2504 - acc: 0.9196\n",
      "Epoch 16/100\n",
      "13106/13106 [==============================] - 3s 264us/step - loss: 0.2325 - acc: 0.9263\n",
      "Epoch 17/100\n",
      "13106/13106 [==============================] - 4s 268us/step - loss: 0.2322 - acc: 0.9264\n",
      "Epoch 18/100\n",
      "13106/13106 [==============================] - 3s 261us/step - loss: 0.2203 - acc: 0.9285\n",
      "Epoch 19/100\n",
      "13106/13106 [==============================] - 3s 253us/step - loss: 0.2272 - acc: 0.9267\n",
      "Epoch 20/100\n",
      "13106/13106 [==============================] - 3s 254us/step - loss: 0.2229 - acc: 0.9281\n",
      "Epoch 21/100\n",
      "13106/13106 [==============================] - 4s 282us/step - loss: 0.2150 - acc: 0.9304\n",
      "Epoch 22/100\n",
      "13106/13106 [==============================] - 4s 285us/step - loss: 0.2040 - acc: 0.9327\n",
      "Epoch 23/100\n",
      "13106/13106 [==============================] - 3s 260us/step - loss: 0.1943 - acc: 0.9365\n",
      "Epoch 24/100\n",
      "13106/13106 [==============================] - 4s 290us/step - loss: 0.1955 - acc: 0.9370\n",
      "Epoch 25/100\n",
      "13106/13106 [==============================] - 4s 323us/step - loss: 0.1949 - acc: 0.9365\n",
      "Epoch 26/100\n",
      "13106/13106 [==============================] - 4s 288us/step - loss: 0.1785 - acc: 0.9417\n",
      "Epoch 27/100\n",
      "13106/13106 [==============================] - 3s 242us/step - loss: 0.1742 - acc: 0.9429\n",
      "Epoch 28/100\n",
      "13106/13106 [==============================] - 3s 248us/step - loss: 0.1782 - acc: 0.9415\n",
      "Epoch 29/100\n",
      "13106/13106 [==============================] - 3s 263us/step - loss: 0.1738 - acc: 0.9429\n",
      "Epoch 30/100\n",
      "13106/13106 [==============================] - 3s 233us/step - loss: 0.1757 - acc: 0.9424\n",
      "Epoch 31/100\n",
      "13106/13106 [==============================] - 4s 267us/step - loss: 0.1640 - acc: 0.9458\n",
      "Epoch 32/100\n",
      "13106/13106 [==============================] - 6s 435us/step - loss: 0.1608 - acc: 0.9479\n",
      "Epoch 33/100\n",
      "13106/13106 [==============================] - 5s 354us/step - loss: 0.1586 - acc: 0.9481\n",
      "Epoch 34/100\n",
      "13106/13106 [==============================] - 5s 393us/step - loss: 0.1623 - acc: 0.9459\n",
      "Epoch 35/100\n",
      "13106/13106 [==============================] - 7s 513us/step - loss: 0.1513 - acc: 0.9505\n",
      "Epoch 36/100\n",
      "13106/13106 [==============================] - 7s 504us/step - loss: 0.1498 - acc: 0.9498\n",
      "Epoch 37/100\n",
      "13106/13106 [==============================] - 6s 491us/step - loss: 0.1555 - acc: 0.9486\n",
      "Epoch 38/100\n",
      "13106/13106 [==============================] - 7s 507us/step - loss: 0.1457 - acc: 0.9535\n",
      "Epoch 39/100\n",
      "13106/13106 [==============================] - 6s 490us/step - loss: 0.1416 - acc: 0.9548\n",
      "Epoch 40/100\n",
      "13106/13106 [==============================] - 6s 474us/step - loss: 0.1387 - acc: 0.9545\n",
      "Epoch 41/100\n",
      "13106/13106 [==============================] - 6s 476us/step - loss: 0.1367 - acc: 0.9535\n",
      "Epoch 42/100\n",
      "13106/13106 [==============================] - 6s 490us/step - loss: 0.1359 - acc: 0.9544\n",
      "Epoch 43/100\n",
      "13106/13106 [==============================] - 6s 487us/step - loss: 0.1371 - acc: 0.9552\n",
      "Epoch 44/100\n",
      "13106/13106 [==============================] - 6s 453us/step - loss: 0.1242 - acc: 0.9583\n",
      "Epoch 45/100\n",
      "13106/13106 [==============================] - 6s 422us/step - loss: 0.1372 - acc: 0.9549\n",
      "Epoch 46/100\n",
      "13106/13106 [==============================] - 5s 376us/step - loss: 0.1234 - acc: 0.9587\n",
      "Epoch 47/100\n",
      "13106/13106 [==============================] - 5s 375us/step - loss: 0.1200 - acc: 0.9606\n",
      "Epoch 48/100\n",
      "13106/13106 [==============================] - 6s 439us/step - loss: 0.1273 - acc: 0.9570\n",
      "Epoch 49/100\n",
      "13106/13106 [==============================] - 5s 396us/step - loss: 0.1342 - acc: 0.9547\n",
      "Epoch 50/100\n",
      "13106/13106 [==============================] - 5s 375us/step - loss: 0.1186 - acc: 0.9618\n",
      "Epoch 51/100\n",
      "13106/13106 [==============================] - 5s 355us/step - loss: 0.1194 - acc: 0.9611\n",
      "Epoch 52/100\n",
      "13106/13106 [==============================] - 5s 346us/step - loss: 0.1144 - acc: 0.9622\n",
      "Epoch 53/100\n",
      "13106/13106 [==============================] - 5s 376us/step - loss: 0.1024 - acc: 0.9669\n",
      "Epoch 54/100\n",
      "13106/13106 [==============================] - 5s 374us/step - loss: 0.1080 - acc: 0.9636\n",
      "Epoch 55/100\n",
      "13106/13106 [==============================] - 5s 395us/step - loss: 0.1122 - acc: 0.9636\n",
      "Epoch 56/100\n",
      "13106/13106 [==============================] - 5s 378us/step - loss: 0.1182 - acc: 0.9596\n",
      "Epoch 57/100\n",
      "13106/13106 [==============================] - 5s 363us/step - loss: 0.1161 - acc: 0.9604\n",
      "Epoch 58/100\n",
      "13106/13106 [==============================] - 5s 369us/step - loss: 0.1136 - acc: 0.9626\n",
      "Epoch 59/100\n",
      "13106/13106 [==============================] - 6s 464us/step - loss: 0.1120 - acc: 0.9625\n",
      "Epoch 60/100\n",
      "13106/13106 [==============================] - 7s 556us/step - loss: 0.1043 - acc: 0.9655\n",
      "Epoch 61/100\n",
      "13106/13106 [==============================] - 6s 455us/step - loss: 0.0967 - acc: 0.9674\n",
      "Epoch 62/100\n",
      "13106/13106 [==============================] - 5s 403us/step - loss: 0.1155 - acc: 0.9615\n",
      "Epoch 63/100\n",
      "13106/13106 [==============================] - 5s 368us/step - loss: 0.1057 - acc: 0.9627\n",
      "Epoch 64/100\n",
      "13106/13106 [==============================] - 5s 377us/step - loss: 0.1014 - acc: 0.9661\n",
      "Epoch 65/100\n",
      "13106/13106 [==============================] - 6s 477us/step - loss: 0.0993 - acc: 0.9695\n",
      "Epoch 66/100\n",
      "13106/13106 [==============================] - 7s 534us/step - loss: 0.0936 - acc: 0.9704\n",
      "Epoch 67/100\n",
      "13106/13106 [==============================] - 4s 320us/step - loss: 0.0971 - acc: 0.9680\n",
      "Epoch 68/100\n",
      "13106/13106 [==============================] - 4s 307us/step - loss: 0.0968 - acc: 0.9683\n",
      "Epoch 69/100\n",
      "13106/13106 [==============================] - 8s 603us/step - loss: 0.0910 - acc: 0.9705\n",
      "Epoch 70/100\n",
      "13106/13106 [==============================] - 13s 990us/step - loss: 0.0952 - acc: 0.9697\n",
      "Epoch 71/100\n",
      "13106/13106 [==============================] - 5s 402us/step - loss: 0.0828 - acc: 0.9722\n",
      "Epoch 72/100\n",
      "13106/13106 [==============================] - 4s 305us/step - loss: 0.0863 - acc: 0.9722\n",
      "Epoch 73/100\n",
      "13106/13106 [==============================] - 4s 300us/step - loss: 0.0994 - acc: 0.9693\n",
      "Epoch 74/100\n",
      "13106/13106 [==============================] - 4s 285us/step - loss: 0.0782 - acc: 0.9754\n",
      "Epoch 75/100\n",
      "13106/13106 [==============================] - 4s 312us/step - loss: 0.0841 - acc: 0.9731\n",
      "Epoch 76/100\n",
      "13106/13106 [==============================] - 4s 277us/step - loss: 0.0990 - acc: 0.9702\n",
      "Epoch 77/100\n",
      "13106/13106 [==============================] - 4s 276us/step - loss: 0.0800 - acc: 0.9735\n",
      "Epoch 78/100\n",
      "13106/13106 [==============================] - 4s 272us/step - loss: 0.0870 - acc: 0.9702\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13106/13106 [==============================] - 3s 254us/step - loss: 0.0794 - acc: 0.9733\n",
      "Epoch 80/100\n",
      "13106/13106 [==============================] - 3s 256us/step - loss: 0.0955 - acc: 0.9686\n",
      "Epoch 81/100\n",
      "13106/13106 [==============================] - 3s 258us/step - loss: 0.0833 - acc: 0.9713\n",
      "Epoch 82/100\n",
      "13106/13106 [==============================] - 3s 253us/step - loss: 0.0811 - acc: 0.9731\n",
      "Epoch 83/100\n",
      "13106/13106 [==============================] - 3s 262us/step - loss: 0.0843 - acc: 0.9725\n",
      "Epoch 84/100\n",
      "13106/13106 [==============================] - 3s 254us/step - loss: 0.0862 - acc: 0.9715\n",
      "Epoch 85/100\n",
      "13106/13106 [==============================] - 3s 255us/step - loss: 0.0824 - acc: 0.9715\n",
      "Epoch 86/100\n",
      "13106/13106 [==============================] - 3s 266us/step - loss: 0.0766 - acc: 0.9750\n",
      "Epoch 87/100\n",
      "13106/13106 [==============================] - 3s 264us/step - loss: 0.0761 - acc: 0.9744\n",
      "Epoch 88/100\n",
      "13106/13106 [==============================] - 3s 256us/step - loss: 0.0767 - acc: 0.9748\n",
      "Epoch 89/100\n",
      "13106/13106 [==============================] - 3s 256us/step - loss: 0.0790 - acc: 0.9737\n",
      "Epoch 90/100\n",
      "13106/13106 [==============================] - 3s 255us/step - loss: 0.0774 - acc: 0.9751\n",
      "Epoch 91/100\n",
      "13106/13106 [==============================] - 3s 254us/step - loss: 0.0776 - acc: 0.9749\n",
      "Epoch 92/100\n",
      "13106/13106 [==============================] - 3s 255us/step - loss: 0.0841 - acc: 0.9730\n",
      "Epoch 93/100\n",
      "13106/13106 [==============================] - 3s 253us/step - loss: 0.0723 - acc: 0.9768\n",
      "Epoch 94/100\n",
      "13106/13106 [==============================] - 3s 255us/step - loss: 0.0724 - acc: 0.9765\n",
      "Epoch 95/100\n",
      "13106/13106 [==============================] - 3s 254us/step - loss: 0.0772 - acc: 0.9738\n",
      "Epoch 96/100\n",
      "13106/13106 [==============================] - 3s 255us/step - loss: 0.0686 - acc: 0.9767\n",
      "Epoch 97/100\n",
      "13106/13106 [==============================] - 3s 260us/step - loss: 0.0737 - acc: 0.9747\n",
      "Epoch 98/100\n",
      "13106/13106 [==============================] - 3s 258us/step - loss: 0.0692 - acc: 0.9772\n",
      "Epoch 99/100\n",
      "13106/13106 [==============================] - 3s 258us/step - loss: 0.0606 - acc: 0.9799\n",
      "Epoch 100/100\n",
      "13106/13106 [==============================] - 4s 276us/step - loss: 0.0626 - acc: 0.9796\n",
      "5618/5618 [==============================] - 2s 291us/step\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Loss**: 0.4299501164658274"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy**: 0.9120683517265931"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "epochs = 200\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 128(relu) - 32(tanh) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(lr), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "printmd(f'**Loss**: {loss}')\n",
    "printmd(f'**Accuracy**: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить динамический (адаптивный) коэффициент обучения. Для этого воспользуемся методом `Adam`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Building with new architecture...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512(relu) - 128(relu) - 32(tanh) - 10(softmax)\n",
      "Learning rate: 0.001\n",
      "Epochs: 100\n",
      "\n",
      "Epoch 1/100\n",
      "13106/13106 [==============================] - 9s 674us/step - loss: 0.8378 - acc: 0.7442\n",
      "Epoch 2/100\n",
      "13106/13106 [==============================] - 6s 468us/step - loss: 0.5344 - acc: 0.8432\n",
      "Epoch 3/100\n",
      "13106/13106 [==============================] - 7s 500us/step - loss: 0.4681 - acc: 0.8613\n",
      "Epoch 4/100\n",
      "13106/13106 [==============================] - 8s 576us/step - loss: 0.4523 - acc: 0.8653\n",
      "Epoch 5/100\n",
      "13106/13106 [==============================] - 8s 596us/step - loss: 0.4151 - acc: 0.8756\n",
      "Epoch 6/100\n",
      "13106/13106 [==============================] - 7s 520us/step - loss: 0.3984 - acc: 0.8814\n",
      "Epoch 7/100\n",
      "13106/13106 [==============================] - 6s 487us/step - loss: 0.3894 - acc: 0.8825\n",
      "Epoch 8/100\n",
      "13106/13106 [==============================] - 6s 486us/step - loss: 0.3865 - acc: 0.8830\n",
      "Epoch 9/100\n",
      "13106/13106 [==============================] - 8s 581us/step - loss: 0.3674 - acc: 0.8875\n",
      "Epoch 10/100\n",
      "13106/13106 [==============================] - 6s 495us/step - loss: 0.3609 - acc: 0.8874\n",
      "Epoch 11/100\n",
      "13106/13106 [==============================] - 6s 491us/step - loss: 0.3543 - acc: 0.8920\n",
      "Epoch 12/100\n",
      "13106/13106 [==============================] - 7s 544us/step - loss: 0.3448 - acc: 0.8927\n",
      "Epoch 13/100\n",
      "13106/13106 [==============================] - 7s 544us/step - loss: 0.3400 - acc: 0.8966\n",
      "Epoch 14/100\n",
      "13106/13106 [==============================] - 7s 513us/step - loss: 0.3341 - acc: 0.8987\n",
      "Epoch 15/100\n",
      "13106/13106 [==============================] - 6s 476us/step - loss: 0.3313 - acc: 0.8981\n",
      "Epoch 16/100\n",
      "13106/13106 [==============================] - 7s 553us/step - loss: 0.3244 - acc: 0.8984\n",
      "Epoch 17/100\n",
      "13106/13106 [==============================] - 7s 509us/step - loss: 0.3275 - acc: 0.8965\n",
      "Epoch 18/100\n",
      "13106/13106 [==============================] - 6s 493us/step - loss: 0.3126 - acc: 0.9002\n",
      "Epoch 19/100\n",
      "13106/13106 [==============================] - 6s 487us/step - loss: 0.3173 - acc: 0.8998\n",
      "Epoch 20/100\n",
      "13106/13106 [==============================] - 6s 487us/step - loss: 0.3092 - acc: 0.9029\n",
      "Epoch 21/100\n",
      "13106/13106 [==============================] - 6s 491us/step - loss: 0.3087 - acc: 0.9038\n",
      "Epoch 22/100\n",
      "13106/13106 [==============================] - 6s 493us/step - loss: 0.2990 - acc: 0.9052\n",
      "Epoch 23/100\n",
      "13106/13106 [==============================] - 7s 497us/step - loss: 0.2998 - acc: 0.9068\n",
      "Epoch 24/100\n",
      "13106/13106 [==============================] - 7s 499us/step - loss: 0.2963 - acc: 0.9083\n",
      "Epoch 25/100\n",
      "13106/13106 [==============================] - 7s 499us/step - loss: 0.2918 - acc: 0.9089\n",
      "Epoch 26/100\n",
      "13106/13106 [==============================] - 7s 567us/step - loss: 0.2757 - acc: 0.9142\n",
      "Epoch 27/100\n",
      "13106/13106 [==============================] - 6s 446us/step - loss: 0.2809 - acc: 0.9112\n",
      "Epoch 28/100\n",
      "13106/13106 [==============================] - 8s 608us/step - loss: 0.2767 - acc: 0.9129\n",
      "Epoch 29/100\n",
      "13106/13106 [==============================] - 7s 545us/step - loss: 0.2787 - acc: 0.9138\n",
      "Epoch 30/100\n",
      "13106/13106 [==============================] - 7s 563us/step - loss: 0.2746 - acc: 0.9125\n",
      "Epoch 31/100\n",
      "13106/13106 [==============================] - 7s 505us/step - loss: 0.2784 - acc: 0.9129\n",
      "Epoch 32/100\n",
      "13106/13106 [==============================] - 7s 514us/step - loss: 0.2621 - acc: 0.9168\n",
      "Epoch 33/100\n",
      "13106/13106 [==============================] - 7s 509us/step - loss: 0.2620 - acc: 0.9178\n",
      "Epoch 34/100\n",
      "13106/13106 [==============================] - 7s 502us/step - loss: 0.2552 - acc: 0.9177\n",
      "Epoch 35/100\n",
      "13106/13106 [==============================] - 7s 517us/step - loss: 0.2597 - acc: 0.9150\n",
      "Epoch 36/100\n",
      "13106/13106 [==============================] - 7s 510us/step - loss: 0.2662 - acc: 0.9164\n",
      "Epoch 37/100\n",
      "13106/13106 [==============================] - 7s 508us/step - loss: 0.2666 - acc: 0.9171\n",
      "Epoch 38/100\n",
      "13106/13106 [==============================] - 7s 509us/step - loss: 0.2538 - acc: 0.9203\n",
      "Epoch 39/100\n",
      "13106/13106 [==============================] - 7s 510us/step - loss: 0.2653 - acc: 0.9158\n",
      "Epoch 40/100\n",
      "13106/13106 [==============================] - 7s 511us/step - loss: 0.2548 - acc: 0.9190\n",
      "Epoch 41/100\n",
      "13106/13106 [==============================] - 7s 516us/step - loss: 0.2471 - acc: 0.9210\n",
      "Epoch 42/100\n",
      "13106/13106 [==============================] - 8s 588us/step - loss: 0.2511 - acc: 0.9207\n",
      "Epoch 43/100\n",
      "13106/13106 [==============================] - 6s 484us/step - loss: 0.2448 - acc: 0.9215\n",
      "Epoch 44/100\n",
      "13106/13106 [==============================] - 6s 482us/step - loss: 0.2483 - acc: 0.9209\n",
      "Epoch 45/100\n",
      "13106/13106 [==============================] - 6s 481us/step - loss: 0.2461 - acc: 0.9224\n",
      "Epoch 46/100\n",
      "13106/13106 [==============================] - 6s 482us/step - loss: 0.2444 - acc: 0.9221\n",
      "Epoch 47/100\n",
      "13106/13106 [==============================] - 6s 484us/step - loss: 0.2479 - acc: 0.9207\n",
      "Epoch 48/100\n",
      "13106/13106 [==============================] - 6s 482us/step - loss: 0.2446 - acc: 0.9226\n",
      "Epoch 49/100\n",
      "13106/13106 [==============================] - 6s 488us/step - loss: 0.2315 - acc: 0.9244\n",
      "Epoch 50/100\n",
      "13106/13106 [==============================] - 6s 489us/step - loss: 0.2387 - acc: 0.9222\n",
      "Epoch 51/100\n",
      "13106/13106 [==============================] - 6s 490us/step - loss: 0.2309 - acc: 0.9274\n",
      "Epoch 52/100\n",
      "13106/13106 [==============================] - 7s 500us/step - loss: 0.2471 - acc: 0.9208\n",
      "Epoch 53/100\n",
      "13106/13106 [==============================] - 8s 604us/step - loss: 0.2342 - acc: 0.9239\n",
      "Epoch 54/100\n",
      "13106/13106 [==============================] - 6s 489us/step - loss: 0.2339 - acc: 0.9255\n",
      "Epoch 55/100\n",
      "13106/13106 [==============================] - 6s 435us/step - loss: 0.2391 - acc: 0.9222\n",
      "Epoch 56/100\n",
      "13106/13106 [==============================] - 7s 558us/step - loss: 0.2252 - acc: 0.9275\n",
      "Epoch 57/100\n",
      "13106/13106 [==============================] - 8s 594us/step - loss: 0.2369 - acc: 0.9237\n",
      "Epoch 58/100\n",
      "13106/13106 [==============================] - 7s 530us/step - loss: 0.2201 - acc: 0.9300\n",
      "Epoch 59/100\n",
      "13106/13106 [==============================] - 7s 511us/step - loss: 0.2279 - acc: 0.9264\n",
      "Epoch 60/100\n",
      "13106/13106 [==============================] - 6s 457us/step - loss: 0.2280 - acc: 0.9290\n",
      "Epoch 61/100\n",
      "13106/13106 [==============================] - 6s 446us/step - loss: 0.2272 - acc: 0.9280\n",
      "Epoch 62/100\n",
      "13106/13106 [==============================] - 6s 461us/step - loss: 0.2205 - acc: 0.9300\n",
      "Epoch 63/100\n",
      "13106/13106 [==============================] - 6s 476us/step - loss: 0.2219 - acc: 0.9283\n",
      "Epoch 64/100\n",
      "13106/13106 [==============================] - 7s 530us/step - loss: 0.2130 - acc: 0.9324\n",
      "Epoch 65/100\n",
      "13106/13106 [==============================] - 6s 452us/step - loss: 0.2226 - acc: 0.9275\n",
      "Epoch 66/100\n",
      "13106/13106 [==============================] - 7s 509us/step - loss: 0.2149 - acc: 0.9324\n",
      "Epoch 67/100\n",
      "13106/13106 [==============================] - 7s 552us/step - loss: 0.2122 - acc: 0.9314\n",
      "Epoch 68/100\n",
      "13106/13106 [==============================] - 7s 556us/step - loss: 0.2188 - acc: 0.9297\n",
      "Epoch 69/100\n",
      "13106/13106 [==============================] - 6s 459us/step - loss: 0.2107 - acc: 0.9311\n",
      "Epoch 70/100\n",
      "13106/13106 [==============================] - 7s 498us/step - loss: 0.2218 - acc: 0.9287\n",
      "Epoch 71/100\n",
      "13106/13106 [==============================] - 8s 581us/step - loss: 0.2089 - acc: 0.9319\n",
      "Epoch 72/100\n",
      "13106/13106 [==============================] - 8s 626us/step - loss: 0.2094 - acc: 0.9341\n",
      "Epoch 73/100\n",
      "13106/13106 [==============================] - 8s 593us/step - loss: 0.2080 - acc: 0.9353\n",
      "Epoch 74/100\n",
      "13106/13106 [==============================] - 8s 617us/step - loss: 0.2301 - acc: 0.9255\n",
      "Epoch 75/100\n",
      "13106/13106 [==============================] - 10s 727us/step - loss: 0.1999 - acc: 0.9346\n",
      "Epoch 76/100\n",
      "13106/13106 [==============================] - 9s 684us/step - loss: 0.2045 - acc: 0.9329\n",
      "Epoch 77/100\n",
      "13106/13106 [==============================] - 9s 665us/step - loss: 0.2005 - acc: 0.9366\n",
      "Epoch 78/100\n",
      "13106/13106 [==============================] - 9s 677us/step - loss: 0.2139 - acc: 0.9299\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13106/13106 [==============================] - 7s 550us/step - loss: 0.2142 - acc: 0.9301\n",
      "Epoch 80/100\n",
      "13106/13106 [==============================] - 7s 528us/step - loss: 0.2044 - acc: 0.9332\n",
      "Epoch 81/100\n",
      "13106/13106 [==============================] - 11s 838us/step - loss: 0.2163 - acc: 0.9303\n",
      "Epoch 82/100\n",
      "13106/13106 [==============================] - 8s 595us/step - loss: 0.2047 - acc: 0.9337\n",
      "Epoch 83/100\n",
      "13106/13106 [==============================] - 9s 649us/step - loss: 0.2066 - acc: 0.9316\n",
      "Epoch 84/100\n",
      "13106/13106 [==============================] - 6s 483us/step - loss: 0.2150 - acc: 0.9303\n",
      "Epoch 85/100\n",
      "13106/13106 [==============================] - 7s 520us/step - loss: 0.2004 - acc: 0.9341\n",
      "Epoch 86/100\n",
      "13106/13106 [==============================] - 8s 590us/step - loss: 0.2025 - acc: 0.9351\n",
      "Epoch 87/100\n",
      "13106/13106 [==============================] - 6s 451us/step - loss: 0.1866 - acc: 0.9413\n",
      "Epoch 88/100\n",
      "13106/13106 [==============================] - 7s 546us/step - loss: 0.1924 - acc: 0.9400\n",
      "Epoch 89/100\n",
      "13106/13106 [==============================] - 7s 513us/step - loss: 0.1921 - acc: 0.9409\n",
      "Epoch 90/100\n",
      "13106/13106 [==============================] - 7s 513us/step - loss: 0.1934 - acc: 0.9375\n",
      "Epoch 91/100\n",
      "13106/13106 [==============================] - 7s 526us/step - loss: 0.1854 - acc: 0.9400\n",
      "Epoch 92/100\n",
      "13106/13106 [==============================] - 7s 525us/step - loss: 0.1947 - acc: 0.9357\n",
      "Epoch 93/100\n",
      "13106/13106 [==============================] - 7s 511us/step - loss: 0.1958 - acc: 0.9357\n",
      "Epoch 94/100\n",
      "13106/13106 [==============================] - 7s 515us/step - loss: 0.2016 - acc: 0.9353\n",
      "Epoch 95/100\n",
      "13106/13106 [==============================] - 7s 522us/step - loss: 0.1947 - acc: 0.9369\n",
      "Epoch 96/100\n",
      "13106/13106 [==============================] - 7s 532us/step - loss: 0.2005 - acc: 0.9353\n",
      "Epoch 97/100\n",
      "13106/13106 [==============================] - 7s 518us/step - loss: 0.1863 - acc: 0.9368\n",
      "Epoch 98/100\n",
      "13106/13106 [==============================] - 7s 557us/step - loss: 0.1960 - acc: 0.9371\n",
      "Epoch 99/100\n",
      "13106/13106 [==============================] - 8s 573us/step - loss: 0.1848 - acc: 0.9413\n",
      "Epoch 100/100\n",
      "13106/13106 [==============================] - 7s 531us/step - loss: 0.1921 - acc: 0.9368\n",
      "5618/5618 [==============================] - 2s 349us/step\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Loss**: 0.33870873077457253"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy**: 0.9133143466577364"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 100\n",
    "printmd('**Building with new architecture...**')\n",
    "print('512(relu) - 128(relu) - 32(tanh) - 10(softmax)')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "loss_method = 'sparse_categorical_crossentropy'\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(lr), \n",
    "              loss=loss_method,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "printmd(f'**Loss**: {loss}')\n",
    "printmd(f'**Accuracy**: {acc}')\n",
    "print('=======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> @chiselko6 </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
